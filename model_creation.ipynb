{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9476f8f3-76ec-4932-b0f7-57ec4b8764f6",
   "metadata": {},
   "source": [
    "## Train a MIDI Generator Model from Scratch\n",
    "\n",
    "This notebook demonstrates training a simple language model from scratch to generate MIDI-like sequences in the \"p:v:d:t\" format.\n",
    "We will use a basic Transformer model and a custom tokenizer tailored for this format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edd16e7-8046-408c-839f-aa4d66b1893c",
   "metadata": {},
   "source": [
    "### 1. Install Libraries\n",
    "\n",
    "```python\n",
    "!pip install datasets transformers[torch]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854e0d4-f5d8-4a34-a627-19e389ba6b25",
   "metadata": {},
   "source": [
    "### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec775598-8abd-4f02-8235-3596203a7250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a56575f-0d11-4aea-83c7-0f4a7499046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    PreTrainedTokenizerFast,\n",
    "    PreTrainedModel,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Config\n",
    ")\n",
    "from typing import List, Dict, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec17f7-4d7f-4f8a-9031-212cc221d6a9",
   "metadata": {},
   "source": [
    "### 3. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b12f23-1b89-47e0-be51-12e4743b7ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a simple tokenizer that recognizes the \"p:v:d:t\" format and special tokens.\n",
    "\n",
    "class SimpleMidiTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocab = {\n",
    "            '<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3,\n",
    "            'p': 4, 'v': 5, 'd': 6, 't': 7, ':': 8,\n",
    "            '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, '9': 18, ' ':19\n",
    "        }\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.eos_token_id = self.vocab['</s>']\n",
    "\n",
    "    def tokenize(self, text: str) -> List[int]:\n",
    "        tokens = []\n",
    "        tokens.append(self.bos_token_id) # Start of sequence token\n",
    "        for element in text.split(' '): # Split by space to get 'p:v:d:t' blocks\n",
    "            if not element: # Skip empty strings if any\n",
    "                continue\n",
    "            for char in element:\n",
    "                if char in self.vocab:\n",
    "                    tokens.append(self.vocab[char])\n",
    "                else:\n",
    "                    tokens.append(self.vocab['<unk>']) # Unknown token\n",
    "            tokens.append(self.vocab[' ']) # Space token to separate note blocks\n",
    "        tokens.pop() # Remove last space token if present\n",
    "        tokens.append(self.eos_token_id) # End of sequence token\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, token_ids: List[int], skip_special_tokens=True) -> str:\n",
    "        text = \"\"\n",
    "        for token_id in token_ids:\n",
    "            if token_id in self.inv_vocab:\n",
    "                token = self.inv_vocab[token_id]\n",
    "                if skip_special_tokens:\n",
    "                    if token not in ['<s>', '</s>', '<pad>']: # Exclude special tokens from decoded text\n",
    "                        text += token\n",
    "                else:\n",
    "                    text += token\n",
    "            else:\n",
    "                text += '<unk>' # Handle unknown token ids if any\n",
    "        return text.replace('  ', ' ') # Clean up double spaces\n",
    "\n",
    "\n",
    "class BinnedQuadrupletMidiTokenizer:\n",
    "    def __init__(self,\n",
    "                 pitch_range: Tuple[int, int] = (0, 127),\n",
    "                 volume_range: Tuple[int, int] = (0, 127),\n",
    "                 duration_range: Tuple[int, int] = (0, 4000), # Example max\n",
    "                 time_range: Tuple[int, int] = (0, 10000),  # Example max\n",
    "                 duration_bins: int = 128, # Number of bins for duration\n",
    "                 time_bins: int = 128      # Number of bins for time\n",
    "                 ):\n",
    "\n",
    "        self.pitch_range = pitch_range\n",
    "        self.volume_range = volume_range\n",
    "        # Store raw ranges and bin counts\n",
    "        self.duration_info = {'range': duration_range, 'bins': duration_bins}\n",
    "        self.time_info = {'range': time_range, 'bins': time_bins}\n",
    "\n",
    "        self.vocab = {\n",
    "            '<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '<note>': 4\n",
    "        }\n",
    "        self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "        self.next_token_id = len(self.vocab)\n",
    "\n",
    "        # Store prefixes\n",
    "        self.prefixes = {\n",
    "            'pitch': '<pitch_', 'volume': '<volume_',\n",
    "            'duration': '<duration_bin_', 'time': '<time_bin_'\n",
    "        }\n",
    "\n",
    "        # --- Add tokens ---\n",
    "        # Pitch and Volume (exact values)\n",
    "        self._add_exact_value_tokens(pitch_range, self.prefixes['pitch'])\n",
    "        self._add_exact_value_tokens(volume_range, self.prefixes['volume'])\n",
    "\n",
    "        # Duration and Time (binned values)\n",
    "        self.duration_boundaries = self._calculate_log_boundaries(duration_range, duration_bins)\n",
    "        self.time_boundaries = self._calculate_log_boundaries(time_range, time_bins)\n",
    "        self._add_bin_tokens(duration_bins, self.prefixes['duration'])\n",
    "        self._add_bin_tokens(time_bins, self.prefixes['time'])\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.pad_token_id = self.vocab['<pad>']\n",
    "        self.bos_token_id = self.vocab['<s>']\n",
    "        self.eos_token_id = self.vocab['</s>']\n",
    "        self.unk_token_id = self.vocab['<unk>']\n",
    "        self.note_token_id = self.vocab['<note>']\n",
    "\n",
    "        # Precompile regex\n",
    "        self.note_pattern = re.compile(r'p(\\d+):v(\\d+):d(\\d+):t(\\d+)')\n",
    "\n",
    "    def _calculate_log_boundaries(self, value_range: Tuple[int, int], num_bins: int) -> np.ndarray:\n",
    "        \"\"\"Calculates logarithmic bin boundaries.\"\"\"\n",
    "        min_val, max_val = value_range\n",
    "        if min_val < 0: min_val = 0 # Ensure non-negative for log\n",
    "        # Add 1 before log, subtract 1 after to handle 0 correctly\n",
    "        # Use logspace from log10(min_val+1) to log10(max_val+1)\n",
    "        boundaries = np.logspace(\n",
    "            np.log10(min_val + 1),\n",
    "            np.log10(max_val + 1),\n",
    "            num=num_bins + 1 # Need num_bins + 1 boundaries for num_bins bins\n",
    "        ) - 1\n",
    "        # Ensure the first boundary is exactly the minimum value if it was >= 0\n",
    "        if min_val >= 0:\n",
    "             boundaries[0] = min_val\n",
    "        return boundaries\n",
    "\n",
    "    def _add_exact_value_tokens(self, value_range: Tuple[int, int], prefix: str):\n",
    "        \"\"\"Adds tokens for each exact value in the range.\"\"\"\n",
    "        for i in range(value_range[0], value_range[1] + 1):\n",
    "            token_name = f'{prefix}{i}>'\n",
    "            self.vocab[token_name] = self.next_token_id\n",
    "            self.inv_vocab[self.next_token_id] = token_name\n",
    "            self.next_token_id += 1\n",
    "\n",
    "    def _add_bin_tokens(self, num_bins: int, prefix: str):\n",
    "        \"\"\"Adds tokens for each bin index.\"\"\"\n",
    "        for i in range(num_bins):\n",
    "            token_name = f'{prefix}{i}>'\n",
    "            self.vocab[token_name] = self.next_token_id\n",
    "            self.inv_vocab[self.next_token_id] = token_name\n",
    "            self.next_token_id += 1\n",
    "\n",
    "    def _get_bin_index(self, value: int, boundaries: np.ndarray) -> int:\n",
    "        \"\"\"Finds the appropriate bin index for a value.\"\"\"\n",
    "        # np.digitize returns the index of the bin (starting from 1)\n",
    "        # boundaries[i-1] <= x < boundaries[i]\n",
    "        bin_index = np.digitize(value, boundaries[1:], right=False) # Use boundaries[1:] because digitize checks < boundary\n",
    "        # Ensure index is within bounds [0, num_bins-1]\n",
    "        return min(bin_index, len(boundaries) - 2) # len(boundaries) - 2 is the max bin index\n",
    "\n",
    "    def _get_value_token_id(self, value: int, value_range: Tuple[int, int], prefix: str) -> int:\n",
    "        \"\"\"Gets the token ID for an exact value.\"\"\"\n",
    "        if value_range[0] <= value <= value_range[1]:\n",
    "            token_name = f'{prefix}{value}>'\n",
    "            return self.vocab.get(token_name, self.unk_token_id)\n",
    "        return self.unk_token_id\n",
    "\n",
    "    def _get_bin_token_id(self, value: int, boundaries: np.ndarray, prefix: str) -> int:\n",
    "        \"\"\"Gets the token ID for a binned value.\"\"\"\n",
    "        min_val = boundaries[0]\n",
    "        max_val = boundaries[-1]\n",
    "        if min_val <= value <= max_val:\n",
    "             bin_index = self._get_bin_index(value, boundaries)\n",
    "             token_name = f'{prefix}{bin_index}>'\n",
    "             return self.vocab.get(token_name, self.unk_token_id) # Should exist, but fallback\n",
    "        return self.unk_token_id\n",
    "\n",
    "    def tokenize(self, text: str) -> List[int]:\n",
    "        tokens = [self.bos_token_id]\n",
    "        note_blocks = text.strip().split(' ')\n",
    "        for block in note_blocks:\n",
    "            if not block: continue\n",
    "            match = self.note_pattern.match(block)\n",
    "            if match:\n",
    "                try:\n",
    "                    p_val = int(match.group(1))\n",
    "                    v_val = int(match.group(2))\n",
    "                    d_val = int(match.group(3))\n",
    "                    t_val = int(match.group(4))\n",
    "\n",
    "                    p_token_id = self._get_value_token_id(p_val, self.pitch_range, self.prefixes['pitch'])\n",
    "                    v_token_id = self._get_value_token_id(v_val, self.volume_range, self.prefixes['volume'])\n",
    "                    d_token_id = self._get_bin_token_id(d_val, self.duration_boundaries, self.prefixes['duration'])\n",
    "                    t_token_id = self._get_bin_token_id(t_val, self.time_boundaries, self.prefixes['time'])\n",
    "\n",
    "                    # Check if any tokenization resulted in UNK\n",
    "                    if all(tid != self.unk_token_id for tid in [p_token_id, v_token_id, d_token_id, t_token_id]):\n",
    "                        tokens.append(self.note_token_id)\n",
    "                        tokens.append(p_token_id)\n",
    "                        tokens.append(v_token_id)\n",
    "                        tokens.append(d_token_id)\n",
    "                        tokens.append(t_token_id)\n",
    "                    else:\n",
    "                        # Handle UNK during tokenization (e.g., value truly out of range)\n",
    "                        tokens.extend([self.unk_token_id] * 5) # Or just one UNK? Depends.\n",
    "                except (ValueError, IndexError):\n",
    "                    tokens.extend([self.unk_token_id] * 5) # Malformed block\n",
    "            else:\n",
    "                 tokens.append(self.unk_token_id) # Non-matching block\n",
    "\n",
    "        tokens.append(self.eos_token_id)\n",
    "        return tokens\n",
    "\n",
    "    def _get_value_from_exact_token(self, token_id: int, prefix: str) -> int | None:\n",
    "        \"\"\"Helper to extract value from exact value token.\"\"\"\n",
    "        token = self.inv_vocab.get(token_id)\n",
    "        if token and token.startswith(prefix) and token.endswith('>'):\n",
    "            try:\n",
    "                return int(token[len(prefix):-1])\n",
    "            except ValueError:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    def _get_approx_value_from_bin_token(self, token_id: int, prefix: str, boundaries: np.ndarray) -> str | None:\n",
    "         \"\"\"Helper to get an approximate representation from bin token.\"\"\"\n",
    "         token = self.inv_vocab.get(token_id)\n",
    "         if token and token.startswith(prefix) and token.endswith('>'):\n",
    "             try:\n",
    "                 bin_index = int(token[len(prefix):-1])\n",
    "                 if 0 <= bin_index < len(boundaries) - 1:\n",
    "                     # Return a string representing the bin range or midpoint\n",
    "                     lower_bound = boundaries[bin_index]\n",
    "                     upper_bound = boundaries[bin_index + 1]\n",
    "                     # Simple representation: midpoint rounded\n",
    "                     midpoint = int(round((lower_bound + upper_bound) / 2))\n",
    "                     # Or return range string: f\"({int(lower_bound)}-{int(upper_bound)})\"\n",
    "                     return str(midpoint) # Return midpoint as string\n",
    "                 else: return \"<bin_idx_err>\"\n",
    "             except ValueError:\n",
    "                 return \"<bin_parse_err>\"\n",
    "         return None\n",
    "\n",
    "\n",
    "    def decode(self, token_ids: List[int], skip_special_tokens: bool = True) -> str:\n",
    "        notes_str = []\n",
    "        i = 0\n",
    "        while i < len(token_ids):\n",
    "            token_id = token_ids[i]\n",
    "            token = self.inv_vocab.get(token_id)\n",
    "\n",
    "            special_tokens_to_handle = ['<s>', '</s>', '<pad>', '<unk>']\n",
    "\n",
    "            if skip_special_tokens and token in special_tokens_to_handle:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if not skip_special_tokens and token in special_tokens_to_handle:\n",
    "                 notes_str.append(token)\n",
    "                 i += 1\n",
    "                 continue\n",
    "\n",
    "            if token == '<note>':\n",
    "                if i + 4 < len(token_ids): # Check for full quadruplet\n",
    "                    p_token_id = token_ids[i+1]\n",
    "                    v_token_id = token_ids[i+2]\n",
    "                    d_token_id = token_ids[i+3]\n",
    "                    t_token_id = token_ids[i+4]\n",
    "\n",
    "                    p_val = self._get_value_from_exact_token(p_token_id, self.prefixes['pitch'])\n",
    "                    v_val = self._get_value_from_exact_token(v_token_id, self.prefixes['volume'])\n",
    "                    # Get approximate value string for duration and time\n",
    "                    d_val_approx = self._get_approx_value_from_bin_token(d_token_id, self.prefixes['duration'], self.duration_boundaries)\n",
    "                    t_val_approx = self._get_approx_value_from_bin_token(t_token_id, self.prefixes['time'], self.time_boundaries)\n",
    "\n",
    "\n",
    "                    if all(v is not None for v in [p_val, v_val, d_val_approx, t_val_approx]):\n",
    "                        notes_str.append(f\"p{p_val}:v{v_val}:d{d_val_approx}:t{t_val_approx}\")\n",
    "                        i += 5 # Move past the <note> and its 4 value tokens\n",
    "                    else:\n",
    "                        # Malformed note sequence after <note>\n",
    "                        if not skip_special_tokens: notes_str.append(\"<unk_note>\")\n",
    "                        i += 1 # Move past the <note> token only\n",
    "                else:\n",
    "                    # Not enough tokens after <note>\n",
    "                    if not skip_special_tokens: notes_str.append(\"<partial_note>\")\n",
    "                    i += 1\n",
    "            else:\n",
    "                 # Unexpected token\n",
    "                 if not skip_special_tokens: notes_str.append(token if token else \"<unk_decode>\")\n",
    "                 i += 1\n",
    "\n",
    "        return \" \".join(notes_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93d141-7a12-4bc9-b3df-b1f517aaa6fb",
   "metadata": {},
   "source": [
    "### 4. Midi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3cf14e-9375-457c-81d4-52d4196a5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_length):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset[idx]['text']\n",
    "        midi_sequence = self._preprocess_text(text) # Preprocess inside dataset\n",
    "        tokenized_sequence = self.tokenizer.tokenize(midi_sequence)\n",
    "        padded_sequence = self._pad_sequence(tokenized_sequence)\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.tokenizer.pad_token_id else -100 for label in padded_sequence]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(padded_sequence),\n",
    "            'labels': torch.tensor(labels) # Labels are same as input_ids for LM\n",
    "        }\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        \"\"\"Removes the system prompt and keeps only the MIDI sequence.\"\"\"\n",
    "        try:\n",
    "            midi_sequence_start = text.find(\"[/INST]\") + len(\"[/INST]\")\n",
    "            midi_sequence_end = text.find(\"</s>\")\n",
    "            if midi_sequence_end != -1: # Handle case where </s> is present\n",
    "                midi_sequence = text[midi_sequence_start:midi_sequence_end].strip()\n",
    "            else: # If </s> is not found, take until the end\n",
    "                midi_sequence = text[midi_sequence_start:].strip()\n",
    "            return midi_sequence\n",
    "        except:\n",
    "            print(f\"Warning: Could not process example: {text[:100]}...\")\n",
    "            return text # Fallback, keep original if processing fails\n",
    "\n",
    "    def _pad_sequence(self, tokenized_sequence):\n",
    "        \"\"\"Pads or truncates a tokenized sequence to max_length.\"\"\"\n",
    "        if len(tokenized_sequence) > self.max_length:\n",
    "            tokenized_sequence = tokenized_sequence[:self.max_length] # Truncate if longer\n",
    "        padding_length = self.max_length - len(tokenized_sequence)\n",
    "        tokenized_sequence.extend([self.tokenizer.pad_token_id] * padding_length)\n",
    "        return tokenized_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9c5c2-2db4-43bf-afbf-6556088a7a46",
   "metadata": {},
   "source": [
    "### 5. Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a668af1-6ca6-47cc-b317-11661387c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dt_ranges(dataset):\n",
    "    \"\"\"\n",
    "    Calculates the minimum and maximum duration (d) and time (t) values\n",
    "    found in the 'text' column of the dataset after preprocessing.\n",
    "    \"\"\"\n",
    "    min_d, max_d = float('inf'), float('-inf')\n",
    "    min_t, max_t = float('inf'), float('-inf')\n",
    "\n",
    "    # Precompile regex for faster parsing\n",
    "    note_pattern = re.compile(r'p(\\d+):v(\\d+):d(\\d+):t(\\d+)') # Slightly more robust\n",
    "\n",
    "    print(\"Calculating duration (d) and time (t) ranges from dataset...\")\n",
    "    for example in tqdm(dataset):\n",
    "        text = example['text']\n",
    "        # --- Preprocessing logic (mirrors MidiDataset._preprocess_text) ---\n",
    "        try:\n",
    "            midi_sequence_start = text.find(\"[/INST]\") + len(\"[/INST]\")\n",
    "            midi_sequence_end = text.find(\"</s>\")\n",
    "            if midi_sequence_end != -1:\n",
    "                midi_sequence = text[midi_sequence_start:midi_sequence_end].strip()\n",
    "            else:\n",
    "                midi_sequence = text[midi_sequence_start:].strip()\n",
    "        except:\n",
    "            # Skip problematic examples during range calculation\n",
    "            continue\n",
    "        # --- End Preprocessing ---\n",
    "\n",
    "        # Find all note matches in the preprocessed sequence\n",
    "        # We can split by space first for potentially better performance on long strings\n",
    "        note_blocks = midi_sequence.split(' ')\n",
    "        for block in note_blocks:\n",
    "            match = note_pattern.match(block) # Use match since we expect it at the start of the block\n",
    "            if match:\n",
    "                try:\n",
    "                    # Extract d and t values as integers\n",
    "                    d_val = int(match.group(3))\n",
    "                    t_val = int(match.group(4))\n",
    "\n",
    "                    # Update min/max\n",
    "                    min_d = min(min_d, d_val)\n",
    "                    max_d = max(max_d, d_val)\n",
    "                    min_t = min(min_t, t_val)\n",
    "                    max_t = max(max_t, t_val)\n",
    "                except (ValueError, IndexError):\n",
    "                    continue\n",
    "\n",
    "    # Handle cases where no valid values were found\n",
    "    if min_d == float('inf'): min_d = 0\n",
    "    if max_d == float('-inf'): max_d = 2000 # Sensible default max if none found\n",
    "    if min_t == float('inf'): min_t = 0\n",
    "    if max_t == float('-inf'): max_t = 2000 # Sensible default max if none found\n",
    "\n",
    "    print(\"Calculation complete.\")\n",
    "    # Ensure min is not greater than max if only one value was found\n",
    "    if min_d > max_d: max_d = min_d\n",
    "    if min_t > max_t: max_t = min_t\n",
    "\n",
    "    return (min_d, max_d), (min_t, max_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c8a8db9-6634-4dc3-9dd9-5931f52a44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_max_t(example, max_t_threshold):\n",
    "    \"\"\"\n",
    "    Checks if all 't' values in a single dataset example are <= max_t_threshold.\n",
    "    Returns True to keep the example, False to discard it.\n",
    "    \"\"\"\n",
    "    text = example['text']\n",
    "    # --- Preprocessing logic ---\n",
    "    try:\n",
    "        midi_sequence_start = text.find(\"[/INST]\") + len(\"[/INST]\")\n",
    "        midi_sequence_end = text.find(\"</s>\")\n",
    "        if midi_sequence_end != -1: midi_sequence = text[midi_sequence_start:midi_sequence_end].strip()\n",
    "        else: midi_sequence = text[midi_sequence_start:].strip()\n",
    "    except: return True # Keep examples where preprocessing fails\n",
    "    # --- End Preprocessing ---\n",
    "\n",
    "    t_pattern = re.compile(r':t(\\d+)')\n",
    "    matches = t_pattern.finditer(midi_sequence)\n",
    "    try:\n",
    "        for match in matches:\n",
    "            t_val = int(match.group(1))\n",
    "            if t_val > max_t_threshold: return False # Discard example\n",
    "    except ValueError: return True # Keep examples with parsing errors\n",
    "    except Exception: return True # Keep on other unexpected errors\n",
    "    return True # Keep if all checks pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed126977-94c5-46b4-8546-f35211f3aff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw dataset split: train[:40000]...\n",
      "Original dataset size: 40000\n",
      "Filtering dataset with max_t_threshold = 10000...\n",
      "Filtered dataset size: 39839\n",
      "Calculating ranges on filtered dataset...\n",
      "Calculating duration (d) and time (t) ranges from dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f779dc428f3d4bd2a05c45e6636acd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation complete.\n",
      "Calculated Duration (d) Range: (0, 4613)\n",
      "Calculated Pause (t) Range: (0, 9993)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"fegounna/GMP_4K\"\n",
    "raw_dataset_split = \"train[:40000]\" # Adjust size as needed\n",
    "dataset = load_dataset(dataset_name, split=raw_dataset_split)\n",
    "MAX_T_THRESHOLD = 10000\n",
    "\n",
    "# --- Load Raw Dataset ---\n",
    "print(f\"Loading raw dataset split: {raw_dataset_split}...\")\n",
    "raw_dataset = load_dataset(dataset_name, split=raw_dataset_split)\n",
    "print(f\"Original dataset size: {len(raw_dataset)}\")\n",
    "\n",
    "# --- Filter Dataset ---\n",
    "print(f\"Filtering dataset with max_t_threshold = {MAX_T_THRESHOLD}...\")\n",
    "filtered_dataset = raw_dataset.filter(\n",
    "    lambda example: filter_by_max_t(example, MAX_T_THRESHOLD)\n",
    ")\n",
    "print(f\"Filtered dataset size: {len(filtered_dataset)}\")\n",
    "\n",
    "# --- Calculate Ranges on FILTERED data ---\n",
    "print(\"Calculating ranges on filtered dataset...\")\n",
    "duration_range, pause_range = calculate_dt_ranges(filtered_dataset) # Use filtered_dataset\n",
    "print(f\"Calculated Duration (d) Range: {duration_range}\")\n",
    "print(f\"Calculated Pause (t) Range: {pause_range}\") # This range should now respect the threshold\n",
    "\n",
    "\n",
    "# Instantiate BINNED Tokenizer using calculated ranges and desired bins\n",
    "DURATION_BINS = 2048 # Control vocab size vs precision trade-off\n",
    "TIME_BINS = 4096   # Control vocab size vs precision trade-off\n",
    "\n",
    "tokenizer = BinnedQuadrupletMidiTokenizer(\n",
    "    duration_range=duration_range,\n",
    "    time_range=pause_range,\n",
    "    duration_bins=DURATION_BINS,\n",
    "    time_bins=TIME_BINS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0e52d89-7100-4967-a5d8-ec6ff7699a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizer vocab size: 6405\n",
      "Dataset size: 40000\n",
      "\n",
      "Example from dataset:\n",
      "Input IDs (first 50): tensor([   1,    4,   86,  211, 1709, 4430,    4,   81,  201, 1489, 3105,    4,\n",
      "          62,  193, 1714, 4552,    4,   89,  220, 1719, 2617,    4,   50,  212,\n",
      "        1718, 2617,    4,   81,  200, 1593, 4445,    4,   86,  212, 1637, 2617,\n",
      "           4,   57,  193, 1718, 4452,    4,   62,  202, 1717, 2925,    4,   81,\n",
      "         206, 1497])\n",
      "Labels (first 50): tensor([   1,    4,   86,  211, 1709, 4430,    4,   81,  201, 1489, 3105,    4,\n",
      "          62,  193, 1714, 4552,    4,   89,  220, 1719, 2617,    4,   50,  212,\n",
      "        1718, 2617,    4,   81,  200, 1593, 4445,    4,   86,  212, 1637, 2617,\n",
      "           4,   57,  193, 1718, 4452,    4,   62,  202, 1717, 2925,    4,   81,\n",
      "         206, 1497])\n",
      "\n",
      "Decoded example (first part): p81:v78:d389:t117 p76:v68:d157:t5 p57:v60:d398:t154 p84:v87:d406:t1 p45:v79:d404:t1 p76:v67:d241:t121 p81:v79:d289:t1 p52:v60:d404:t123 p57:v69:d402:t3 p76:v73:d162:t159 p84:v90:d402:t1 p45:v72:d402:t...\n"
     ]
    }
   ],
   "source": [
    "# Create the training dataset using the tokenizer\n",
    "train_dataset = MidiDataset(dataset, tokenizer, max_length=512)\n",
    "\n",
    "print(\"\\nTokenizer vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Dataset size:\", len(train_dataset))\n",
    "example_dataset = train_dataset[0]\n",
    "print(\"\\nExample from dataset:\")\n",
    "print(\"Input IDs (first 50):\", example_dataset['input_ids'][:50])\n",
    "print(\"Labels (first 50):\", example_dataset['labels'][:50])\n",
    "decoded_example = tokenizer.decode(example_dataset['input_ids'].tolist())\n",
    "print(\"\\nDecoded example (first part):\", decoded_example[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91008268-a1f5-4207-b67d-2df1ca69b693",
   "metadata": {},
   "source": [
    "### 6. Build a Simple Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "def0aaf5-cc75-41ad-a2da-54b11c42b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 13303680\n"
     ]
    }
   ],
   "source": [
    "# We create a small GPT-2 like model configuration and instantiate the model.\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_embd=384,      # Embedding dimension\n",
    "    n_head=6,        # Number of attention heads\n",
    "    n_layer=6,       # Number of layers\n",
    "    n_positions=512, # Max sequence length - adjust if needed\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "print(f\"Model parameters: {model.num_parameters()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd738ec-1864-4fe5-a09f-4a33864f938a",
   "metadata": {},
   "source": [
    "### 7. Set up Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3a1de1-3b8d-4539-b4e3-121c863f571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# We define training arguments and the Trainer.\n",
    "\n",
    "output_dir = \"./models\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=6,\n",
    "    per_device_train_batch_size=16,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=500,\n",
    "    learning_rate=5e-4,\n",
    "    # lr_scheduler_type='cosine_with_restarts', # Optional learning rate scheduler\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    report_to=None, # No wandb for simple notebook\n",
    "    fp16=False,      # Set to True if using GPU with FP16 support\n",
    "    bf16=False,      # Set to True if using GPU with BF16 support (e.g., Ampere GPUs)\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9feb2a-8375-44dc-8822-7a6c3cf2b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 8. Train the Model\n",
    "\n",
    "trainer.train(resume_from_checkpoint=False)\n",
    "\n",
    "# ### 9. Save Trained Model and Tokenizer\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db57b79-17ef-4e86-af6e-25781762db64",
   "metadata": {},
   "source": [
    "### 10. Example Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39da1978-886f-47f5-9fc3-03d562829d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sequence with Nucleus Sampling (top_p=0.95, temp=0.9)...\n",
      "Prompt length: 2 tokens, Max new tokens: 510, Total max length: 512\n",
      "\n",
      "--- Generated MIDI Sequence ---\n",
      "p63:v55:d4:t1 p70:v77:d11:t2 p58:v61:d57:t5 p76:v65:d11:t5 p59:v63:d4:t676 p71:v91:d4604:t3 p71:v81:d4604:t0 p59:v70:d4604:t1 p59:v67:d4604:t4 p59:v69:d4604:t1 p62:v58:d4604:t1 p59:v57:d4:t613 p54:v47:d4604:t1 p59:v46:d9:t1 p54:v51:d4604:t5 p66:v52:d4170:t3 p83:v74:d4585:t5 p63:v68:d3840:t1 p66:v70:d4274:t0 p66:v70:d4187:t3 p87:v73:d4604:t2 p71:v70:d4604:t0 p59:v67:d4604:t1 p78:v70:d4604:t3 p59:v69:d4604:t1 p54:v61:d11:t0 p58:v67:d4547:t0 p64:v67:d5:t2 p66:v73:d4604:t8 p58:v65:d4604:t1197 p61:v66:d4604:t1 p54:v66:d4604:t8 p54:v66:d4604:t6 p70:v82:d4604:t0 p58:v63:d4604:t1 p64:v71:d4604:t0 p54:v67:d4604:t1 p73:v85:d4604:t0 p58:v73:d4604:t1 p54:v65:d4604:t5 p61:v66:d4604:t4 p54:v68:d4604:t5 p59:v70:d4454:t658 p78:v100:d3777:t5 p64:v73:d4292:t2 p54:v62:d3888:t5 p47:v58:d3640:t0 p54:v58:d4604:t7 p59:v69:d4604:t4 p54:v65:d4604:t1 p59:v63:d4604:t1 p58:v69:d4604:t5 p76:v64:d4604:t0 p76:v75:d4604:t8 p66:v68:d4604:t7 p58:v62:d4604:t4 p78:v82:d4604:t4 p85:v79:d4604:t5 p66:v69:d4604:t8 p54:v60:d4604:t0 p58:v62:d3872:t5 p66:v66:d4604:t9 p58:v60:d4604:t7 p54:v59:d4604:t664 p56:v74:d3888:t2 p56:v68:d4604:t6 p58:v64:d4274:t0 p61:v59:d4:t0 p54:v62:d4205:t1 p61:v64:d4585:t2 p52:v66:d3777:t0 p59:v67:d3777:t2 p71:v79:d3670:t0 p62:v78:d4604:t1 p54:v64:d4510:t2 p64:v67:d4239:t655 p47:v72:d4604:t2 p47:v59:d4239:t1 p59:v67:d4035:t1 p66:v73:d4328:t2 p61:v63:d4604:t1 p52:v58:d5:t1 p47:v56:d4604:t3 p54:v53:d4604:t1 p52:v49:d4604:t4 p58:v50:d4604:t2 p63:v59:d4604:t1 p54:v60:d4604:t686 p59:v79:d4604:t0 p66:v84:d4604:t1 p54:v68:d3888:t2 p64:v75:d9:t2 p58:v64:d12:t1\n",
      "--- End of Sequence ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming 'tokenizer', 'trainer' are already defined and the model is loaded\n",
    "\n",
    "def generate_midi_sequence_nucleus(\n",
    "    prompt_text: str = \"\",\n",
    "    max_new_tokens: int = 256, # Renamed for clarity: generates this many NEW tokens\n",
    "    top_p: float = 0.9,        # Nucleus sampling probability threshold (e.g., 0.85, 0.9, 0.95)\n",
    "    temperature: float = 0.8,  # Optional: slight temperature can smooth probabilities before top_p\n",
    "    device = None\n",
    "):\n",
    "    \"\"\"Generates MIDI sequence using nucleus sampling.\"\"\"\n",
    "\n",
    "    if device is None:\n",
    "      device = trainer.model.device # Use the model's device by default\n",
    "\n",
    "    input_tokens = tokenizer.tokenize(prompt_text)\n",
    "    input_tensor = torch.tensor([input_tokens]).to(device)\n",
    "    input_length = input_tensor.shape[1] # Length of the prompt tokens\n",
    "\n",
    "    # Calculate the total max_length for the generate function\n",
    "    total_max_length = input_length + max_new_tokens\n",
    "\n",
    "    print(f\"Generating sequence with Nucleus Sampling (top_p={top_p}, temp={temperature})...\")\n",
    "    print(f\"Prompt length: {input_length} tokens, Max new tokens: {max_new_tokens}, Total max length: {total_max_length}\")\n",
    "\n",
    "    generated_token_ids = trainer.model.generate(\n",
    "        input_tensor,\n",
    "        max_length=total_max_length,    # Total desired sequence length\n",
    "        do_sample=True,                 # MUST be True for sampling strategies\n",
    "        top_p=top_p,                    # Enable nucleus sampling\n",
    "        temperature=temperature,        # Control randomness (1.0 = no change)\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Extract only the generated tokens (excluding the prompt)\n",
    "    generated_part_ids = generated_token_ids[0, input_length:]\n",
    "\n",
    "    # Decode the generated part\n",
    "    generated_sequence = tokenizer.decode(generated_part_ids.tolist(), skip_special_tokens=True) # Skip special tokens for cleaner output\n",
    "\n",
    "    return generated_sequence.strip() # Remove leading/trailing whitespace\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "prompt = \"\" # Start generation from scratch\n",
    "# Let's generate approximately 510 *new* tokens\n",
    "# Note: Tokenizer adds BOS/EOS, so actual number might vary slightly depending on tokenizer implementation\n",
    "max_new_tokens_to_generate = 510\n",
    "\n",
    "generated_midi = generate_midi_sequence_nucleus(\n",
    "    prompt_text=prompt,\n",
    "    max_new_tokens=max_new_tokens_to_generate,\n",
    "    top_p=0.95,       # Common value for nucleus sampling\n",
    "    temperature=0.9  # Slightly reduced temperature often works well with top_p\n",
    ")\n",
    "\n",
    "print(f\"\\n--- Generated MIDI Sequence ---\")\n",
    "print(generated_midi)\n",
    "print(f\"--- End of Sequence ---\")\n",
    "\n",
    "# To generate the midi file use text_to_midi.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
